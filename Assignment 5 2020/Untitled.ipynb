{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = \"This is a test string. It is a test string. A very nice test string. I hope you enjoy this test string.\" #We want to pretrain an AI system on text data\n",
    "block_size = 128 #This is the size of the tensor we send the sentence into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test string. It is a test string. A very nice test string. I hope you enjoy this test string.\n",
      "This is a test string. It is a test string. A\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# I'm writing an AI model that takes in wikipedia data on famous people and tries to predict\n",
    "# from a description where the famous person was born\n",
    "# The data looks like this:\n",
    "\n",
    "x: Where was Khatchig Mouradian born?⁇Lebanon⁇□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□\n",
    "\n",
    "# The answer is at the end of the sentence, and then we take the sentence out, and the answer just becomes the target\n",
    "\n",
    "y: □□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□⁇Lebanon⁇□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□\n",
    "\n",
    "# We want to \"corrupt\" the sentence, so the first thing we do is randomly truncate the sentence\n",
    "# but I want to make sure it's not smaller than 4 characters, and not longer than 7/8 of the block_size\n",
    "'''\n",
    "\n",
    "document = test_string[:random.randint(4,int(block_size*7/8))]\n",
    "print(test_string)\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test string. It is a test string. A very nice test string. ⁇I hope you enjoy this test st⁇ring.□□□□□□□□□□□□□□□□□□□□□□□\n",
      "T⁇his is a ⁇test string. It is a test s□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□\n",
      "This is a test string. It is a test string. A ⁇very nice test s⁇tring□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□\n",
      "Thi⁇s ⁇is a t□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□\n",
      "This is a test string. ⁇It is a test str⁇ing. A very nice test string. □□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□\n",
      "This is a test string. It is a test strin⁇g. A very nice test s⁇tring. I hope you enjoy this test string.□□□□□□□□□□□□□□□□□□□□□□□\n",
      "This is a test string.⁇ It is a t⁇est strin□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□\n",
      "This is a test string. It is a test s⁇tring. A very ⁇nice test □□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□\n",
      "This is a test string. It is a te⁇st string. A very nice te⁇st string. I hope you enjoy this test string.□□□□□□□□□□□□□□□□□□□□□□□\n",
      "This is⁇ a t⁇est s□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□\n"
     ]
    }
   ],
   "source": [
    "MASK_CHAR = u\"\\u2047\" #Double Question Mark Character\n",
    "PAD_CHAR = u\"\\u25A1\" #Pad character\n",
    "\n",
    "# I'm just generating 10 random corruptions, which is why I'm using a for loop\n",
    "for i in range(10):\n",
    "    #Re-truncating so you can see the effect on each sentence\n",
    "    document = test_string[:random.randint(4,int(block_size*7/8))]\n",
    "    #Sample a random window size, which will become the size of the target\n",
    "    r_size = random.gauss(.25, .03)\n",
    "    #Find the center index of the target\n",
    "    r_idx = random.uniform((r_size/2),1-(r_size/2))\n",
    "    #place the first mask character r_size/2 below the center index\n",
    "    mask_1 = int(len(document)*(r_idx-(r_size/2)))\n",
    "    #Plac e the seond mask character r_size/2 below the center index\n",
    "    mask_2 = int(len(document)*(r_idx+(r_size/2)))\n",
    "    #Join the parts together and pad the remaining white space (block_size - length of document -2)\n",
    "    #Subtract 2 because we added 2 masked characters\n",
    "    print(''.join([document[:mask_1], MASK_CHAR, document[mask_1:mask_2],\n",
    "        MASK_CHAR, document[mask_2:], PAD_CHAR*(block_size-len(document)-2)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(128, 128, 256)\n",
    "\n",
    "# B = Batch Size\n",
    "# T = Sequence Length\n",
    "# C = Embeding Size\n",
    "B, T, C = X.size()\n",
    "\n",
    "n_embd = 256\n",
    "n_head = 8\n",
    "block_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-7.2175e-04, -4.1507e-04, -6.6582e-04,  ..., -5.3857e-04,\n",
       "          5.7601e-04,  2.3573e-04],\n",
       "        [-4.1511e-04, -3.0242e-04, -7.4655e-04,  ...,  5.7731e-04,\n",
       "         -7.8054e-04, -3.0395e-04],\n",
       "        [-8.4347e-04, -3.5446e-04, -4.9797e-04,  ...,  5.9881e-04,\n",
       "          9.7359e-04,  4.0340e-04],\n",
       "        ...,\n",
       "        [-6.3570e-04, -6.0424e-04,  4.3990e-04,  ..., -1.0673e-04,\n",
       "          1.1454e-05,  7.5907e-04],\n",
       "        [-7.8225e-04,  5.6429e-04,  3.5070e-04,  ...,  5.6131e-04,\n",
       "         -5.3707e-04, -4.8799e-04],\n",
       "        [ 3.8860e-04, -5.1318e-04,  5.4712e-04,  ..., -1.0840e-04,\n",
       "          8.9250e-04, -7.9351e-04]], requires_grad=True)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = torch.nn.Linear(n_embd, n_embd)\n",
    "w2 = torch.nn.Parameter(torch.zeros(n_embd // n_head, block_size-1))\n",
    "b2 = torch.nn.Parameter(torch.zeros(block_size-1))\n",
    "value = torch.nn.Linear(n_embd, n_embd)\n",
    "torch.nn.init.uniform_(w2,-0.001,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 8, 128, 32])\n",
      "torch.Size([1, 1, 32, 127])\n",
      "torch.Size([128, 8, 128, 127])\n",
      "torch.Size([128, 8, 128, 32])\n",
      "torch.Size([128, 8, 32, 128])\n"
     ]
    }
   ],
   "source": [
    "# We want a TxT output\n",
    "\n",
    "wA = torch.relu(w1(X).view(B, T, n_head, C // n_head).transpose(1,2))\n",
    "print(wA.shape)\n",
    "print(w2.unsqueeze(0).unsqueeze(0).shape)\n",
    "print((wA @ w2.unsqueeze(0).unsqueeze(0) + b2).shape)\n",
    "v = value(X).view(B, T, n_head, C // n_head).transpose(1, 2)\n",
    "print(v.shape)\n",
    "print(v.transpose(-2, -1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor to have size 127 at dimension 1, but got size 128 for argument #2 'batch2' (while checking arguments for bmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-274-d81bb2f32485>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matt\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor to have size 127 at dimension 1, but got size 128 for argument #2 'batch2' (while checking arguments for bmm)"
     ]
    }
   ],
   "source": [
    "y = att @ v\n",
    "print(y.transpose(1, 2).shape)\n",
    "y = y.transpose(1, 2).contiguous().view(B, T, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 8, 128, 128])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
